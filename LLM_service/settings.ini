# ═══════════════════════════════════════════════════════════════════════════════
# LLM Workflow Microservice Configuration
# ═══════════════════════════════════════════════════════════════════════════════
#
# Purpose: Configuration file for the LLM-powered workflow execution microservice
# Format: INI configuration with environment variable substitution
# Environment Variables: Use ${VAR_NAME} syntax or ${VAR_NAME:default_value}
#
# Configuration Categories:
#   - DEFAULT: Global application settings
#   - database: PostgreSQL connection pooling
#   - redis: Redis caching and message broker
#   - celery: Asynchronous task queue configuration
#   - api: FastAPI web service settings
#   - openrouter: OpenRouter API for LLM calls (Claude, GPT, etc.)
#   - google: Google Cloud Platform services (Places API)
#   - weatherapi: WeatherAPI.com integration
#   - external_services: Rate limiting and caching for external APIs
#
# ═══════════════════════════════════════════════════════════════════════════════

[DEFAULT]
# ───────────────────────────────────────────────────────────────────────────────
# Global Application Settings
# ───────────────────────────────────────────────────────────────────────────────

# ENVIRONMENT: Deployment environment identifier
# Values: development | staging | production
# Impact:
#   - development: Enables debug mode, verbose logging, CORS permissive
#   - production: Disables debug, restricts CORS, optimizes performance
ENVIRONMENT=development

# LOG_LEVEL: Application-wide logging verbosity
# Values: DEBUG | INFO | WARNING | ERROR | CRITICAL
# Hierarchy: DEBUG (all) > INFO (default) > WARNING > ERROR > CRITICAL (minimal)
# Recommendations:
#   - Development: DEBUG or INFO (detailed for troubleshooting)
#   - Production: WARNING (reduces log volume, focuses on issues)
LOG_LEVEL=INFO

# DEBUG_MODE: Enable debug mode for error handling
# Values: true | false
# Default: false (production-safe)
# Impact:
#   - true: Includes full stack traces in error context (development)
#   - false: Excludes stack traces from error context (production)
# Purpose: Controls sensitive debugging information in error messages
# Security: NEVER set to true in production (exposes internal system details)
# Recommendations:
#   - Development: true (detailed debugging information)
#   - Staging: false (test production error format)
#   - Production: false (REQUIRED - prevents information disclosure)
DEBUG_MODE=false


[database]
# ───────────────────────────────────────────────────────────────────────────────
# PostgreSQL Database Connection Pool
# ───────────────────────────────────────────────────────────────────────────────

# DATABASE_URL: PostgreSQL connection string (required, no default)
# Format: postgresql://user:password@host:port/database
# Example: postgresql://llm_user:secure_pass@localhost:5432/llm_workflow
# Security: Load from environment variable (never commit credentials)
# Usage: Main application database (workflows, tasks, cache, etc.)
DATABASE_URL=${DATABASE_URL}

# POOL_SIZE: Number of persistent connections maintained in pool
# Default: 10 connections
# Calculation: (expected_concurrent_requests / request_duration_seconds) * 1.2
# Recommendations:
#   - Low traffic (<100 req/min): 5-10
#   - Medium traffic (100-1000 req/min): 10-20
#   - High traffic (>1000 req/min): 20-50
# Trade-offs:
#   - Too low: Connection starvation, increased latency
#   - Too high: Database resource exhaustion, memory overhead
POOL_SIZE=10

# MAX_OVERFLOW: Additional connections beyond POOL_SIZE when needed
# Default: 20 connections
# Total max connections: POOL_SIZE + MAX_OVERFLOW (10 + 20 = 30)
# Behavior:
#   - Under normal load: Uses POOL_SIZE connections (reused)
#   - During traffic spikes: Creates up to MAX_OVERFLOW temporary connections
#   - Temporary connections: Closed after use (not returned to pool)
# Recommendations:
#   - 2x POOL_SIZE for moderate spikes (default: 20)
#   - 3-5x POOL_SIZE for high variance traffic
MAX_OVERFLOW=20

# POOL_TIMEOUT: Seconds to wait for available connection before raising error
# Default: 30 seconds
# Behavior:
#   - If all connections busy, waits up to POOL_TIMEOUT for one to free
#   - Timeout exceeded → raises TimeoutError
# Recommendations:
#   - 30s: Good balance (catches issues without excessive waits)
#   - 5-10s: Fail fast for low-latency requirements
#   - 60s+: High concurrency with long-running queries (use with caution)
POOL_TIMEOUT=30

# POOL_RECYCLE: Seconds before recycling idle connections (prevents stale connections)
# Default: 3600 seconds (1 hour)
# Purpose: Avoids "connection has been closed by server" errors
# Database Defaults:
#   - PostgreSQL default wait_timeout: 8 hours
#   - Supabase pooler timeout: ~60 minutes
# Recommendations:
#   - Set to 50-75% of database server's connection timeout
#   - Default 3600s (1 hour) works for most PostgreSQL deployments
#   - Cloud databases: 1800-3600s (30-60 minutes)
POOL_RECYCLE=3600


[redis]
# ───────────────────────────────────────────────────────────────────────────────
# Redis Configuration (Caching + Celery Message Broker)
# ───────────────────────────────────────────────────────────────────────────────

# REDIS_URL: Redis server connection string
# Format: redis://[password@]host:port
# Default: redis://localhost:6379 (if environment variable not set)
# Examples:
#   - Local: redis://localhost:6379
#   - Password-protected: redis://:mypassword@localhost:6379
#   - TLS: rediss://user:password@redis.example.com:6380
# Security: Use Redis AUTH (password) in production
REDIS_URL=${REDIS_URL:redis://localhost:6379}

# REDIS_DB: Redis database number (0-15 available by default)
# Default: 0
# Purpose: Logical database separation within same Redis instance
# Usage:
#   - 0: Application cache (this service)
#   - 1: Celery task results
#   - 2: Session storage
# Performance: No isolation or performance difference between databases
REDIS_DB=0


[celery]
# ───────────────────────────────────────────────────────────────────────────────
# Celery Asynchronous Task Queue Configuration
# ───────────────────────────────────────────────────────────────────────────────

# BROKER_URL: Message broker for task distribution
# Default: Same as REDIS_URL (uses Redis as broker)
# Alternatives: RabbitMQ (amqp://), AWS SQS, etc.
# Purpose: Queue for pending tasks sent by API → consumed by Celery workers
BROKER_URL=${REDIS_URL:redis://localhost:6379}

# RESULT_BACKEND: Storage for task results and state
# Default: Same as REDIS_URL (uses Redis for results)
# Alternatives: PostgreSQL, MongoDB, etc.
# Purpose:
#   - Stores task return values
#   - Tracks task state (PENDING, STARTED, SUCCESS, FAILURE)
#   - Enables task.get() blocking calls to retrieve results
RESULT_BACKEND=${REDIS_URL:redis://localhost:6379}

# TASK_SERIALIZER: Serialization format for task arguments
# Default: json
# Options: json | pickle | yaml | msgpack
# Security: NEVER use 'pickle' with untrusted data (RCE risk)
# Recommendation: Use 'json' (secure, portable, human-readable)
TASK_SERIALIZER=json

# RESULT_SERIALIZER: Serialization format for task return values
# Default: json (same as TASK_SERIALIZER)
# Options: json | pickle | yaml | msgpack
# Recommendation: Match TASK_SERIALIZER for consistency
RESULT_SERIALIZER=json

# ACCEPT_CONTENT: Whitelist of allowed content types (security)
# Default: json (only accept JSON serialized tasks)
# Multiple: json,msgpack,yaml (comma-separated)
# Security: Restricts deserialization to safe formats (prevents pickle exploits)
ACCEPT_CONTENT=json

# TIMEZONE: Task scheduling and timestamp timezone
# Default: UTC (recommended for global applications)
# Options: Any IANA timezone (e.g., America/New_York, Europe/London)
# Impact:
#   - All task ETAs, countdowns, and crontabs use this timezone
#   - Recommendation: Always use UTC, convert to local in application layer
TIMEZONE=UTC

# ENABLE_UTC: Force all timestamps to UTC (even if TIMEZONE differs)
# Default: true (recommended)
# Values: true | false
# Recommendation: Keep true to prevent timezone-related bugs
ENABLE_UTC=true

# TASK_TRACK_STARTED: Record when tasks begin execution (not just queued)
# Default: true
# Values: true | false
# Impact:
#   - true: Task state transitions PENDING → STARTED → SUCCESS/FAILURE
#   - false: Task state jumps PENDING → SUCCESS/FAILURE (no STARTED state)
# Use case: Monitoring task execution duration vs. queue wait time
TASK_TRACK_STARTED=true

# TASK_TIME_LIMIT: Hard time limit for task execution (seconds)
# Default: 3600 seconds (1 hour)
# Behavior: Task forcibly terminated after this duration (SIGKILL)
# Purpose: Prevents runaway tasks from consuming resources indefinitely
# Recommendations:
#   - Workflow execution: 3600s (1 hour)
#   - Quick API calls: 300s (5 minutes)
#   - Long-running ML/AI: 7200s (2 hours)
TASK_TIME_LIMIT=3600

# TASK_SOFT_TIME_LIMIT: Soft time limit for graceful shutdown (seconds)
# Default: 3300 seconds (55 minutes, 5 min before hard limit)
# Behavior: Raises SoftTimeLimitExceeded exception (task can catch and cleanup)
# Formula: TASK_TIME_LIMIT - 300 (5 minutes grace period)
# Purpose: Allows task to save state, cleanup resources before forced termination
TASK_SOFT_TIME_LIMIT=3300


[api]
# ───────────────────────────────────────────────────────────────────────────────
# FastAPI Web Service Configuration
# ───────────────────────────────────────────────────────────────────────────────

# API_TITLE: API documentation title (shown in OpenAPI/Swagger UI)
# Default: LLM Workflow Microservice
# Usage: Displayed in /docs endpoint and API schema
API_TITLE=LLM Workflow Microservice

# API_VERSION: Semantic versioning for API (major.minor.patch)
# Default: 1.0.0
# Usage:
#   - Displayed in API docs
#   - Used for API versioning (e.g., /api/v1, /api/v2)
# Versioning Strategy:
#   - Major (1.0.0): Breaking changes (incompatible with previous version)
#   - Minor (1.1.0): New features (backward compatible)
#   - Patch (1.0.1): Bug fixes (backward compatible)
API_VERSION=1.0.0

# API_PREFIX: URL prefix for all API routes
# Default: /api/v1
# Examples:
#   - /api/v1/workflows → http://localhost:8000/api/v1/workflows
#   - /api/v1/tasks → http://localhost:8000/api/v1/tasks
# Versioning: Include version in prefix for API evolution (v1, v2, etc.)
API_PREFIX=/api/v1

# CORS_ORIGINS: Comma-separated list of allowed origins for CORS
# Default: http://localhost:3000,http://localhost:3001 (Next.js dev servers)
# Format: http://domain:port,https://other-domain
# Security:
#   - Development: Permissive (localhost:*)
#   - Production: Restrict to actual frontend domains only
# Examples:
#   - Development: http://localhost:3000,http://localhost:3001
#   - Production: https://app.example.com,https://www.example.com
# Wildcard (*): NEVER use in production (security risk)
CORS_ORIGINS=http://localhost:3000,http://localhost:3001


[openrouter]
# ───────────────────────────────────────────────────────────────────────────────
# OpenRouter API Configuration (LLM Provider Gateway)
# ───────────────────────────────────────────────────────────────────────────────

# API_KEY: OpenRouter API authentication key (required)
# Format: sk-or-v1-... (prefix may vary)
# Security: Load from environment variable (never commit)
# Purpose: Authenticates requests to OpenRouter for LLM access
# Get key: https://openrouter.ai/keys
# Cost: Pay-as-you-go based on model usage (see OpenRouter pricing)
API_KEY=${OPENROUTER_API_KEY}

# BASE_URL: OpenRouter API base endpoint
# Default: https://openrouter.ai/api/v1
# Purpose: Root URL for all LLM API requests
# Compatibility: OpenAI-compatible API (drop-in replacement)
# Endpoints:
#   - /chat/completions (streaming + non-streaming)
#   - /models (list available models)
# Note: Rarely needs changing unless using self-hosted OpenRouter instance
BASE_URL=https://openrouter.ai/api/v1


[google]
# ───────────────────────────────────────────────────────────────────────────────
# Google Cloud Platform Services Configuration
# ───────────────────────────────────────────────────────────────────────────────

# PLACES_API_KEY: Google Places API authentication key
# Format: AIza... (Google API key prefix)
# Security: Load from environment variable (shared with Next.js frontend)
# Purpose: Access Google Places API for location searches
# Required APIs (enable in Google Cloud Console):
#   - Places API (New)
#   - Maps JavaScript API
#   - Geocoding API
# Pricing: $17 per 1000 requests (Nearby Search)
# Free tier: $200/month credit (~11,764 requests)
# Get key: https://console.cloud.google.com/apis/credentials
# Restrictions: Limit to your domains in production
PLACES_API_KEY=${NEXT_PUBLIC_GOOGLE_SERVICES_API_KEY}


[weatherapi]
# ───────────────────────────────────────────────────────────────────────────────
# WeatherAPI.com Integration Configuration
# ───────────────────────────────────────────────────────────────────────────────

# API_KEY: WeatherAPI.com authentication key
# Format: Varies (alphanumeric string)
# Security: Load from environment variable
# Purpose: Real-time weather data for emergency planning
# Endpoints used:
#   - /current.json (current weather)
#   - /forecast.json (future weather, 1-14 days)
# Pricing: Free tier (1M calls/month), Paid tiers available
# Get key: https://www.weatherapi.com/signup.aspx
API_KEY=${NEXT_PUBLIC_WEATHERAPI_API_KEY}

# BASE_URL: WeatherAPI.com API base endpoint
# Default: https://api.weatherapi.com/v1
# Purpose: Root URL for all weather API requests
# Endpoints:
#   - /current.json?q={location}
#   - /forecast.json?q={location}&days={1-14}
# Note: Rarely needs changing (official endpoint)
BASE_URL=https://api.weatherapi.com/v1


[external_services]
# ───────────────────────────────────────────────────────────────────────────────
# External API Rate Limiting and Caching Configuration
# ───────────────────────────────────────────────────────────────────────────────

# ─── Rate Limiting (requests per hour) ────────────────────────────────────────

# RATE_LIMIT_PER_USER: Maximum requests per user per hour
# Default: 10 requests/hour per user
# Purpose: Prevents individual users from abusing external APIs
# Scope: Per-user quota (tracked by user_id)
# Enforcement: Token bucket algorithm (in-memory tracking)
# Recommendations:
#   - Free tier users: 10/hour
#   - Paid tier users: 100/hour
#   - Enterprise: 1000/hour or unlimited
# Trade-offs:
#   - Too low: Poor UX, legitimate use blocked
#   - Too high: API costs spike, abuse risk
RATE_LIMIT_PER_USER=10

# RATE_LIMIT_GLOBAL: Maximum total requests per hour (all users combined)
# Default: 100 requests/hour globally
# Purpose: Protects against total API quota exhaustion
# Scope: Service-wide quota (all users combined)
# Calculation: Consider API provider limits and budget
# Examples:
#   - Google Places free tier: $200/month credit ≈ 11,764 requests/month ≈ 16/hour
#   - WeatherAPI free tier: 1M requests/month ≈ 1,369/hour
# Recommendations:
#   - Set to 50-75% of provider's actual limit (safety margin)
#   - Monitor usage and adjust based on traffic patterns
RATE_LIMIT_GLOBAL=100

# ─── Cache Settings (time-to-live in seconds) ────────────────────────────────

# CACHE_TTL_DEFAULT: Default cache expiration time (seconds)
# Default: 604800 seconds (7 days)
# Purpose: How long external API responses stay cached before refresh
# Two-level cache: Memory (LRU) + Database (PostgreSQL)
# Trade-offs:
#   - Longer TTL: Lower API costs, possibly stale data
#   - Shorter TTL: Fresher data, higher API costs
# Recommendations by data type:
#   - Static data (place details): 30 days (2,592,000s)
#   - Semi-static (nearby places): 7 days (604800s) - default
#   - Dynamic (weather current): 1 hour (3600s)
#   - Real-time (traffic): 5 minutes (300s)
# Cost Impact (Google Places @ $17/1000 requests):
#   - 7-day cache + 85% hit rate: Saves ~$14.45 per 1000 requests
CACHE_TTL_DEFAULT=604800

# CACHE_MEMORY_SIZE: Number of entries in in-memory LRU cache
# Default: 500 entries
# Purpose: Fast L1 cache (sub-millisecond access) before database lookup
# Architecture: OrderedDict with LRU eviction policy
# Memory usage: ~500KB - 5MB (depends on response size)
# Calculation: (avg_response_size_kb * CACHE_MEMORY_SIZE) + overhead
# Example: 2KB avg response × 500 entries = ~1MB memory
# Recommendations:
#   - Low traffic: 100-500 entries
#   - Medium traffic: 500-2000 entries
#   - High traffic: 2000-10000 entries (monitor memory usage)
# Trade-offs:
#   - Larger cache: Better hit rate, more memory usage
#   - Smaller cache: Lower memory, more database lookups
CACHE_MEMORY_SIZE=500

# ─── Service Enable/Disable Flags ─────────────────────────────────────────────

# GOOGLE_PLACES_ENABLED: Toggle Google Places API integration
# Default: true
# Values: true | false
# Purpose: Feature flag for Google Places service
# Use cases:
#   - Disable during maintenance or API issues
#   - Disable in environments without API key (testing)
#   - Disable to prevent API costs during development
GOOGLE_PLACES_ENABLED=true

# WEATHERAPI_ENABLED: Toggle WeatherAPI.com integration
# Default: true
# Values: true | false
# Purpose: Feature flag for weather data service
# Use cases:
#   - Disable during weather API outages
#   - Disable in testing environments
#   - Disable to reduce API calls during development
WEATHERAPI_ENABLED=true
